{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-23T18:45:20.864151Z","iopub.execute_input":"2021-07-23T18:45:20.864572Z","iopub.status.idle":"2021-07-23T18:45:25.803625Z","shell.execute_reply.started":"2021-07-23T18:45:20.864481Z","shell.execute_reply":"2021-07-23T18:45:25.802655Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = tf.keras.preprocessing.image_dataset_from_directory(\n    '/kaggle/input/alzheimers-audio/VBSDdataset/VBSDdataset/imagetrain',\n    labels=\"inferred\",\n    label_mode=\"binary\",\n    color_mode=\"rgb\",\n    batch_size=32,\n    image_size=(295, 295),\n    shuffle=True,\n    validation_split=0.2,\n    subset=\"training\",\n    seed=54,\n    interpolation=\"bilinear\",\n    follow_links=False,\n)\ntest = tf.keras.preprocessing.image_dataset_from_directory(\n    '/kaggle/input/alzheimers-audio/VBSDdataset/VBSDdataset/imagetrain',\n    labels=\"inferred\",\n    label_mode=\"binary\",\n    color_mode=\"rgb\",\n    batch_size=32,\n    image_size=(295, 295),\n    shuffle=True,\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=54,\n    interpolation=\"bilinear\",\n    follow_links=False,\n)\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:17:29.776229Z","iopub.execute_input":"2021-07-15T02:17:29.7766Z","iopub.status.idle":"2021-07-15T02:17:30.068903Z","shell.execute_reply.started":"2021-07-15T02:17:29.776566Z","shell.execute_reply":"2021-07-15T02:17:30.06817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:17:49.125983Z","iopub.execute_input":"2021-07-15T02:17:49.126305Z","iopub.status.idle":"2021-07-15T02:17:49.130449Z","shell.execute_reply.started":"2021-07-15T02:17:49.126273Z","shell.execute_reply":"2021-07-15T02:17:49.12953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = (\n    train\n    .map(convert_to_float)\n)\ntest = (\n    test\n    .map(convert_to_float)\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:17:51.318335Z","iopub.execute_input":"2021-07-15T02:17:51.318662Z","iopub.status.idle":"2021-07-15T02:17:51.37023Z","shell.execute_reply.started":"2021-07-15T02:17:51.31863Z","shell.execute_reply":"2021-07-15T02:17:51.369402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Keras CNN Model","metadata":{}},{"cell_type":"code","source":"\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n    keras.layers.Conv2D(32, (3, 3), activation=\"sigmoid\", input_shape=(295, 295, 3)),\n    keras.layers.BatchNormalization(),\n\n    keras.layers.Conv2D(32, (3, 3), activation=\"sigmoid\", padding='same'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.20),\n    \n    keras.layers.Conv2D(32, (3, 3), activation=\"sigmoid\", padding='same'),\n    keras.layers.BatchNormalization(),\n    keras.layers.Dropout(0.2),\n\n    keras.layers.Flatten(),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(32, activation=\"sigmoid\"),\n    keras.layers.Dense(1, activation=\"sigmoid\")\n])\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:17:54.018848Z","iopub.execute_input":"2021-07-15T02:17:54.019173Z","iopub.status.idle":"2021-07-15T02:17:54.274332Z","shell.execute_reply.started":"2021-07-15T02:17:54.019143Z","shell.execute_reply":"2021-07-15T02:17:54.273555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import SGD\nmodel.compile(\n    optimizer=SGD(lr=0.01),\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],\n)\n\nhistory = model.fit(\n    train,\n    validation_data=test,\n    epochs=20,\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-15T02:17:57.675125Z","iopub.execute_input":"2021-07-15T02:17:57.675462Z","iopub.status.idle":"2021-07-15T02:17:57.719424Z","shell.execute_reply.started":"2021-07-15T02:17:57.67543Z","shell.execute_reply":"2021-07-15T02:17:57.717059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(history.history.keys())\nplt.plot(history.history['binary_accuracy'])\nplt.plot(history.history['val_binary_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T21:25:53.024429Z","iopub.execute_input":"2021-07-11T21:25:53.024764Z","iopub.status.idle":"2021-07-11T21:25:53.306957Z","shell.execute_reply.started":"2021-07-11T21:25:53.024734Z","shell.execute_reply":"2021-07-11T21:25:53.306043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SciKit RegressionCV Model","metadata":{}},{"cell_type":"code","source":"import os, cv2, itertools\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n!pip install tensorflow.io\nimport tensorflow_io as tfio","metadata":{"execution":{"iopub.status.busy":"2021-07-23T18:45:35.488816Z","iopub.execute_input":"2021-07-23T18:45:35.489172Z","iopub.status.idle":"2021-07-23T18:46:36.315208Z","shell.execute_reply.started":"2021-07-23T18:45:35.489140Z","shell.execute_reply":"2021-07-23T18:46:36.314110Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting tensorflow.io\n  Downloading tensorflow_io-0.19.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (22.7 MB)\n\u001b[K     |████████████████████████████████| 22.7 MB 19.6 MB/s eta 0:00:01\n\u001b[?25hCollecting tensorflow<2.6.0,>=2.5.0\n  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n\u001b[K     |████████████████████████████████| 454.3 MB 14 kB/s s eta 0:00:01    |█▍                              | 20.0 MB 38.1 MB/s eta 0:00:12     |██▏                             | 31.5 MB 10.9 MB/s eta 0:00:39     |██▍                             | 34.6 MB 10.9 MB/s eta 0:00:39     |████▉                           | 69.3 MB 39.3 MB/s eta 0:00:10     |███████▏                        | 101.4 MB 39.3 MB/s eta 0:00:09     |█████████▌                      | 135.3 MB 44.1 MB/s eta 0:00:08     |█████████████████████▉          | 309.4 MB 44.6 MB/s eta 0:00:04\n\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.19.0\n  Downloading tensorflow_io_gcs_filesystem-0.19.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.3 MB)\n\u001b[K     |████████████████████████████████| 2.3 MB 52.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (3.3.0)\nRequirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (0.12.0)\nRequirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (1.12.1)\nRequirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (1.1.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (3.15.8)\nRequirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (1.19.5)\nCollecting h5py~=3.1.0\n  Downloading h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n\u001b[K     |████████████████████████████████| 4.0 MB 35.6 MB/s eta 0:00:01\n\u001b[?25hCollecting keras-nightly~=2.5.0.dev\n  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n\u001b[K     |████████████████████████████████| 1.2 MB 46.9 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (1.15.0)\nCollecting gast==0.4.0\n  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (0.36.2)\nRequirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (1.1.2)\nCollecting grpcio~=1.34.0\n  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n\u001b[K     |████████████████████████████████| 4.0 MB 47.1 MB/s eta 0:00:01\n\u001b[?25hCollecting tensorboard~=2.5\n  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n\u001b[K     |████████████████████████████████| 6.0 MB 39.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (3.7.4.3)\nRequirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (1.6.3)\nCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n\u001b[K     |████████████████████████████████| 462 kB 34.2 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (1.12)\nRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.6.0,>=2.5.0->tensorflow.io) (0.2.0)\nCollecting cached-property\n  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (1.8.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (1.0.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (0.4.3)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[K     |████████████████████████████████| 4.9 MB 52.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (3.3.4)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (1.26.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (2.25.1)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (49.6.0.post20210108)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (4.7.2)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (4.2.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (0.2.7)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (1.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (3.4.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (0.4.8)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (2020.12.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (1.26.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (2.10)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (3.0.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow<2.6.0,>=2.5.0->tensorflow.io) (3.4.1)\nInstalling collected packages: tensorboard-data-server, grpcio, cached-property, tensorflow-estimator, tensorboard, keras-nightly, h5py, gast, tensorflow-io-gcs-filesystem, tensorflow, tensorflow.io\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.32.0\n    Uninstalling grpcio-1.32.0:\n      Successfully uninstalled grpcio-1.32.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.4.0\n    Uninstalling tensorflow-estimator-2.4.0:\n      Successfully uninstalled tensorflow-estimator-2.4.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.4.1\n    Uninstalling tensorboard-2.4.1:\n      Successfully uninstalled tensorboard-2.4.1\n  Attempting uninstall: h5py\n    Found existing installation: h5py 2.10.0\n    Uninstalling h5py-2.10.0:\n      Successfully uninstalled h5py-2.10.0\n  Attempting uninstall: gast\n    Found existing installation: gast 0.3.3\n    Uninstalling gast-0.3.3:\n      Successfully uninstalled gast-0.3.3\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.4.1\n    Uninstalling tensorflow-2.4.1:\n      Successfully uninstalled tensorflow-2.4.1\nSuccessfully installed cached-property-1.5.2 gast-0.4.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorflow-2.5.0 tensorflow-estimator-2.5.0 tensorflow-io-gcs-filesystem-0.19.0 tensorflow.io\n","output_type":"stream"}]},{"cell_type":"code","source":"VBSD_dir1 = '../input/alzheimers-audio/VBSDdataset/VBSDdataset/imagetrain/0/' # Directory for training set\nVBSD_dir2 = '../input/alzheimers-audio/VBSDdataset/VBSDdataset/imagetrain/1/' # Directory for training set\nDemCare_dir1 = '../input/alzheimers-audio/DemCare_imagedata/imagedata/imagetrain/0/' # Directory for testing set\nDemCare_dir2 = '../input/alzheimers-audio/DemCare_imagedata/imagedata/imagetrain/1/' # Directory for testing set","metadata":{"execution":{"iopub.status.busy":"2021-07-23T18:46:58.976416Z","iopub.execute_input":"2021-07-23T18:46:58.976799Z","iopub.status.idle":"2021-07-23T18:46:58.982621Z","shell.execute_reply.started":"2021-07-23T18:46:58.976764Z","shell.execute_reply":"2021-07-23T18:46:58.981563Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nVBSD_train_images1 = [VBSD_dir1+i for i in os.listdir(VBSD_dir1)] \nVBSD_train_images2 = [VBSD_dir2+i for i in os.listdir(VBSD_dir2)]\nDemCare_train_images1 =  [DemCare_dir1+i for i in os.listdir(DemCare_dir1)]\nDemCare_train_images2 =  [DemCare_dir2+i for i in os.listdir(DemCare_dir2)]\n#print(train_images)\ndef read_image(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n   # print(file_path)\n   # print(img.shape)\n    imgg = cv2.resize(img, (295, 295), interpolation=cv2.INTER_CUBIC)\n    time_mask = tfio.audio.time_mask(imgg, param=10)\n    #freq_mask = tfio.audio.freq_mask(img, param=10)\n    return imgg, time_mask#, freq_mask\ndef read_image_noaugment(file_path):\n    img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n    #print(img.shape)\n   # print(file_path)\n    imgg = cv2.resize(img, (295, 295), interpolation=cv2.INTER_CUBIC)\n    return imgg\n\n\ndef prep_data(images, val):    \n    m = len(images) * 2\n    n_x = 295 * 295 * 3\n    \n    X = np.ndarray((n_x, m), dtype=np.uint8)\n    y = np.zeros((1, m))\n    print (\"X shape is {}\".format(X.shape))\n    \n    for i, image_file in enumerate(images):\n        #print(image_file)\n        f = i * 2\n        image, image_time_mask = read_image(image_file)\n        X[:, f] = np.squeeze(image.reshape((n_x, 1)))   \n        X[:, f + 1] = np.squeeze(image.reshape((n_x, 1))) \n        if val == 0:\n            y[0, f] = 0\n            y[0, f + 1] = 0\n        elif val == 1:\n            y[0, f] = 1\n            y[0, f + 1] = 1\n        if f%50 == 0: print('Processed {} of {}'.format(f, m))\n    \n    return X.transpose(), y.flatten()\n\ndef prep_data_noaugment(images, val):    \n    m = len(images)\n    n_x = 295 * 295 * 3\n    \n    X = np.ndarray((n_x, m), dtype=np.uint8)\n    y = np.zeros((1, m))\n    print (\"X shape is {}\".format(X.shape))\n    \n    for i, image_file in enumerate(images):\n        #print(image_file)\n        image = read_image_noaugment(image_file)\n\n        X[:, i] = np.squeeze(image.reshape((n_x, 1)))   \n        if val == 0:\n            y[0, i] = 0\n        elif val == 1:\n            y[0,  i] = 1\n        if i%50 == 0: print('Processed {} of {}'.format(i, m))\n    \n    return X.transpose(), y.flatten()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T18:50:45.813945Z","iopub.execute_input":"2021-07-23T18:50:45.814262Z","iopub.status.idle":"2021-07-23T18:50:45.831920Z","shell.execute_reply.started":"2021-07-23T18:50:45.814233Z","shell.execute_reply":"2021-07-23T18:50:45.830559Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"X_train1, y_train1 = prep_data(VBSD_train_images1, 0)\nX_train2, y_train2 = prep_data(VBSD_train_images2, 1)\nX_t = np.concatenate((X_train1, X_train2),axis = 0)\ny_t = np.concatenate([y_train1, y_train2])\nX_train, X_test, y_train, y_test = train_test_split(X_t, y_t, test_size=0.20, random_state=42)\n\nX_newtrain1, y_newtrain1 = prep_data_noaugment(DemCare_train_images1, 0)\nX_newtrain2, y_newtrain2 = prep_data_noaugment(DemCare_train_images2, 1)\nX_newtrain = np.concatenate((X_newtrain1, X_newtrain2),axis = 0)\ny_newtrain = np.concatenate([y_newtrain1, y_newtrain2])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-23T18:50:48.555812Z","iopub.execute_input":"2021-07-23T18:50:48.556131Z","iopub.status.idle":"2021-07-23T18:51:02.896007Z","shell.execute_reply.started":"2021-07-23T18:50:48.556103Z","shell.execute_reply":"2021-07-23T18:51:02.895074Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"X shape is (261075, 500)\nProcessed 0 of 500\nProcessed 50 of 500\nProcessed 100 of 500\nProcessed 150 of 500\nProcessed 200 of 500\nProcessed 250 of 500\nProcessed 300 of 500\nProcessed 350 of 500\nProcessed 400 of 500\nProcessed 450 of 500\nX shape is (261075, 508)\nProcessed 0 of 508\nProcessed 50 of 508\nProcessed 100 of 508\nProcessed 150 of 508\nProcessed 200 of 508\nProcessed 250 of 508\nProcessed 300 of 508\nProcessed 350 of 508\nProcessed 400 of 508\nProcessed 450 of 508\nProcessed 500 of 508\nX shape is (261075, 231)\nProcessed 0 of 231\nProcessed 50 of 231\nProcessed 100 of 231\nProcessed 150 of 231\nProcessed 200 of 231\nX shape is (261075, 254)\nProcessed 0 of 254\nProcessed 50 of 254\nProcessed 100 of 254\nProcessed 150 of 254\nProcessed 200 of 254\nProcessed 250 of 254\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\nclf = LogisticRegressionCV(cv=5, random_state=0, max_iter = 2000).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T18:51:13.519012Z","iopub.execute_input":"2021-07-23T18:51:13.519330Z","iopub.status.idle":"2021-07-23T19:18:23.299544Z","shell.execute_reply.started":"2021-07-23T18:51:13.519300Z","shell.execute_reply":"2021-07-23T19:18:23.297955Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nsgd_clf = SGDClassifier(random_state=0, max_iter=1000, tol=1e-3).fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T21:04:42.307032Z","iopub.status.idle":"2021-07-11T21:04:42.307898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(X_test, y_test, clf):\n    correct = 0\n    total = 0\n    num_rows, num_col = X_test.shape\n    for i in range(num_rows):\n        x = X_test[i].reshape(1,-1)\n        #print(x.shape)\n        y = y_test[i]\n        y_hat = clf.predict(x)\n        if y_hat == y:\n            correct += 1 \n        total += 1\n    #print(correct, \" / \", total)\n    print(\"Model was\", str(correct*100/total) + \"% correct\")","metadata":{"execution":{"iopub.status.busy":"2021-07-23T19:20:39.978815Z","iopub.execute_input":"2021-07-23T19:20:39.979149Z","iopub.status.idle":"2021-07-23T19:20:39.987778Z","shell.execute_reply.started":"2021-07-23T19:20:39.979118Z","shell.execute_reply":"2021-07-23T19:20:39.986923Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test(X_test, y_test, clf)\n#test(X_newtrain2, y_newtrain2, clf)\n#test(X_test, y_test, sgd_clf)","metadata":{"execution":{"iopub.status.busy":"2021-07-23T19:20:42.054959Z","iopub.execute_input":"2021-07-23T19:20:42.055319Z","iopub.status.idle":"2021-07-23T19:20:42.179444Z","shell.execute_reply.started":"2021-07-23T19:20:42.055267Z","shell.execute_reply":"2021-07-23T19:20:42.177496Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model was 97.02970297029702% correct\n","output_type":"stream"}]}]}